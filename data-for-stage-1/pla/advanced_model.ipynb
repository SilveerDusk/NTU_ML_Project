{
 "cells": [
  {
   "cell_type": "code",
   "id": "fb0533815e492174",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-20T06:01:20.586803Z",
     "start_time": "2024-11-20T06:01:20.423251Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load data\n",
    "train_data = pd.read_csv('../split_data/train_test_data.csv')\n",
    "test_data = pd.read_csv('../split_data/validation_data.csv')\n",
    "\n",
    "print(f\"Training data size: {len(train_data)}, Test data size: {len(test_data)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 9960, Test data size: 1107\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Pre-process the data, for both training and validation",
   "id": "85a8bf899c47dde5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T06:01:22.142935Z",
     "start_time": "2024-11-20T06:01:22.140286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Preprocessing function\n",
    "def preprocess_data(data):\n",
    "    # Drop non-predictive columns\n",
    "    drop_cols = ['id', 'date']\n",
    "    data = data.drop(columns=drop_cols, errors='ignore')\n",
    "    \n",
    "    # Handle categorical variables\n",
    "    categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "    label_encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        data[col] = le.fit_transform(data[col].astype(str))\n",
    "        label_encoders[col] = le  # Save encoders if needed later\n",
    "    \n",
    "    # Handle missing values\n",
    "    data = data.fillna(data.median(numeric_only=True))\n",
    "    \n",
    "    return data, label_encoders"
   ],
   "id": "44db4ba3620017d6",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training the data and saving the model to a file",
   "id": "5fe057e11b6d8ef5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T06:11:11.309904Z",
     "start_time": "2024-11-20T06:01:25.065176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Preprocess train and test data\n",
    "train_data, train_encoders = preprocess_data(train_data)\n",
    "test_data, _ = preprocess_data(test_data)\n",
    "\n",
    "# Split features and target\n",
    "X_train = train_data.drop(columns=['home_team_win'])\n",
    "y_train = train_data['home_team_win']\n",
    "\n",
    "X_test = test_data.drop(columns=['home_team_win'])\n",
    "y_test = test_data['home_team_win']\n",
    "\n",
    "# Build a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Feature scaling\n",
    "    ('model', RandomForestClassifier(random_state=42, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200, 300],\n",
    "    'model__max_depth': [10, 20, None],\n",
    "    'model__min_samples_split': [2, 5, 10],\n",
    "    'model__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Save the trained model\n",
    "model_filename = 'best_random_forest_model.pkl'\n",
    "joblib.dump(best_model, model_filename)\n",
    "print(f\"Model saved to {model_filename}\")\n",
    "\n",
    "# Cross-validation performance\n",
    "cv_scores = cross_val_score(best_model, X_train, y_train, cv=5)\n",
    "print(f\"Cross-Validation Accuracy: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
    "\n",
    "# Load the model and evaluate on test data\n",
    "loaded_model = joblib.load(model_filename)\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature Importance\n",
    "importances = loaded_model.named_steps['model'].feature_importances_\n",
    "feature_names = X_train.columns\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(\"Top 10 Important Features:\\n\", importance_df.head(10))\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Model saved to best_random_forest_model.pkl\n",
      "Cross-Validation Accuracy: 0.5472 ± 0.0073\n",
      "Test Accuracy: 0.5709\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.53      0.49      0.51       504\n",
      "        True       0.60      0.64      0.62       603\n",
      "\n",
      "    accuracy                           0.57      1107\n",
      "   macro avg       0.57      0.56      0.56      1107\n",
      "weighted avg       0.57      0.57      0.57      1107\n",
      "\n",
      "Top 10 Important Features:\n",
      "                                  Feature  Importance\n",
      "25   away_pitching_SO_batters_faced_10RA    0.011180\n",
      "113  away_pitching_SO_batters_faced_mean    0.010860\n",
      "149   away_pitcher_SO_batters_faced_mean    0.008849\n",
      "44                 home_team_spread_mean    0.008672\n",
      "23   home_pitching_BB_batters_faced_10RA    0.008520\n",
      "92     home_pitching_earned_run_avg_mean    0.008229\n",
      "77         away_batting_onbase_perc_mean    0.008216\n",
      "47                 away_team_spread_mean    0.008085\n",
      "52                   home_team_wins_skew    0.008018\n",
      "33    away_pitcher_SO_batters_faced_10RA    0.007991\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluating Performance via Validation Data",
   "id": "d08e6c10219e1fd0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T06:14:48.602433Z",
     "start_time": "2024-11-20T06:14:48.457587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the trained model\n",
    "model_filename = 'best_random_forest_model.pkl'\n",
    "try:\n",
    "    loaded_model = joblib.load(model_filename)\n",
    "    print(f\"Model loaded successfully from {model_filename}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Model file not found: {model_filename}\")\n",
    "    exit()\n",
    "\n",
    "# Load test data here\n",
    "try:\n",
    "    test_data = pd.read_csv('../split_data/validation_data.csv')\n",
    "    print(f\"Test data loaded successfully\")\n",
    "except FileNotFoundError as fe:\n",
    "    print(f\"Test data file not found {fe}\")\n",
    "    exit()\n",
    "\n",
    "# Preprocess test data\n",
    "# Assuming label_encoders were not saved; preprocessing will handle encoding afresh\n",
    "test_data, _ = preprocess_data(test_data)\n",
    "\n",
    "# Separate features and target\n",
    "X_test = test_data.drop(columns=['home_team_win'], errors='ignore')\n",
    "y_test = test_data['home_team_win'] if 'home_team_win' in test_data else None\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "if y_test is not None:\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "else:\n",
    "    print(\"Target variable not found in test data. Predictions only:\")\n",
    "    print(y_pred)\n"
   ],
   "id": "f643a374a8b3b7b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from best_random_forest_model.pkl\n",
      "Test data loaded successfully\n",
      "Test Accuracy: 0.5709\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.53      0.49      0.51       504\n",
      "        True       0.60      0.64      0.62       603\n",
      "\n",
      "    accuracy                           0.57      1107\n",
      "   macro avg       0.57      0.56      0.56      1107\n",
      "weighted avg       0.57      0.57      0.57      1107\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "173cf2551c5538a0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
