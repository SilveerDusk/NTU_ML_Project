{
 "cells": [
  {
   "cell_type": "code",
   "id": "fb0533815e492174",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-21T03:51:23.913600Z",
     "start_time": "2024-11-21T03:51:23.722649Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load data\n",
    "train_data = pd.read_csv('../split_data/train_test_data.csv')\n",
    "test_data = pd.read_csv('../split_data/validation_data.csv')\n",
    "\n",
    "print(f\"Training data size: {len(train_data)}, Test data size: {len(test_data)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 9960, Test data size: 1107\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Pre-process the data, for both training and validation",
   "id": "85a8bf899c47dde5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T03:51:29.794523Z",
     "start_time": "2024-11-21T03:51:29.788613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def preprocess_data(data, target_column):\n",
    "    \"\"\"\n",
    "    Preprocesses data for use in machine learning pipelines.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Input data.\n",
    "        target_column (str): The name of the target column.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Preprocessed data with numeric and encoded features.\n",
    "        pd.Series: Target values.\n",
    "        dict: Encoders for categorical columns.\n",
    "    \"\"\"\n",
    "    # Handle missing values and convert categorical columns\n",
    "    label_encoders = {}\n",
    "    categorical_cols = data.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    # Encode categorical columns\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        data[col] = le.fit_transform(data[col].astype(str).fillna(\"missing\"))\n",
    "        label_encoders[col] = le  # Save the encoder for future use\n",
    "    \n",
    "    # Fill missing numeric values with the median\n",
    "    numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "    data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].median())\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    # Split features and target\n",
    "    X = data.drop(columns=[target_column])\n",
    "    y = data[target_column]\n",
    "    y = le.fit_transform(y)\n",
    "    \n",
    "    return X, y, label_encoders\n"
   ],
   "id": "44db4ba3620017d6",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training the data and saving the model to a file",
   "id": "5fe057e11b6d8ef5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T04:00:54.509162Z",
     "start_time": "2024-11-21T03:51:30.811252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "X_train, y_train, label_encoders = preprocess_data(train_data, \"home_team_win\")\n",
    "\n",
    "\n",
    "# Build a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Feature scaling\n",
    "    ('feature_selection', SelectFromModel(XGBClassifier(eval_metric='logloss'))),\n",
    "    ('model', XGBClassifier(eval_metric='logloss', random_state=42))\n",
    "])\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'feature_selection__estimator__n_estimators': [50, 100, 200],\n",
    "    'feature_selection__estimator__max_depth': [3, 5, 7],\n",
    "    'model__n_estimators': [100, 200, 300],\n",
    "    'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'model__max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Save and evaluate\n",
    "model_filename = 'best_xgboost_model.pkl'\n",
    "joblib.dump(grid_search.best_estimator_, model_filename)\n",
    "print(f\"Model saved to {model_filename}\")\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chuajerome/anaconda3/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to best_xgboost_model.pkl\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluating Performance via Validation Data",
   "id": "d08e6c10219e1fd0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T04:02:17.012787Z",
     "start_time": "2024-11-21T04:02:16.751489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the trained model\n",
    "model_filename = 'best_random_forest_model.pkl'\n",
    "try:\n",
    "    loaded_model = joblib.load(model_filename)\n",
    "    print(f\"Model loaded successfully from {model_filename}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Model file not found: {model_filename}\")\n",
    "    exit()\n",
    "\n",
    "# Load test data here\n",
    "try:\n",
    "    test_data = pd.read_csv('../split_data/validation_data.csv')\n",
    "    print(f\"Test data loaded successfully\")\n",
    "except FileNotFoundError as fe:\n",
    "    print(f\"Test data file not found {fe}\")\n",
    "    exit()\n",
    "\n",
    "# Preprocess test data\n",
    "# Assuming label_encoders were not saved; preprocessing will handle encoding afresh\n",
    "test_data, _, _ = preprocess_data(train_data, \"home_team_win\")\n",
    "\n",
    "# Separate features and target\n",
    "X_test = test_data.drop(columns=['home_team_win'], errors='ignore')\n",
    "y_test = test_data['home_team_win'] if 'home_team_win' in test_data else None\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "if y_test is not None:\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "else:\n",
    "    print(\"Target variable not found in test data. Predictions only:\")\n",
    "    print(y_pred)\n"
   ],
   "id": "f643a374a8b3b7b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from best_random_forest_model.pkl\n",
      "Test data loaded successfully\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- away_batting_RBI_10RA\n- away_batting_RBI_mean\n- away_batting_RBI_skew\n- away_batting_RBI_std\n- away_batting_batting_avg_10RA\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[60], line 27\u001B[0m\n\u001B[1;32m     24\u001B[0m y_test \u001B[38;5;241m=\u001B[39m test_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhome_team_win\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhome_team_win\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m test_data \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# Predict and evaluate\u001B[39;00m\n\u001B[0;32m---> 27\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mloaded_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_test \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     30\u001B[0m     accuracy \u001B[38;5;241m=\u001B[39m accuracy_score(y_test, y_pred)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/pipeline.py:480\u001B[0m, in \u001B[0;36mPipeline.predict\u001B[0;34m(self, X, **predict_params)\u001B[0m\n\u001B[1;32m    478\u001B[0m Xt \u001B[38;5;241m=\u001B[39m X\n\u001B[1;32m    479\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _, name, transform \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iter(with_final\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m--> 480\u001B[0m     Xt \u001B[38;5;241m=\u001B[39m \u001B[43mtransform\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mXt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    481\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m][\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mpredict(Xt, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpredict_params)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/_set_output.py:142\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[0;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 142\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    143\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    144\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[1;32m    145\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[1;32m    146\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[1;32m    147\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[1;32m    148\u001B[0m         )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:992\u001B[0m, in \u001B[0;36mStandardScaler.transform\u001B[0;34m(self, X, copy)\u001B[0m\n\u001B[1;32m    989\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    991\u001B[0m copy \u001B[38;5;241m=\u001B[39m copy \u001B[38;5;28;01mif\u001B[39;00m copy \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcopy\n\u001B[0;32m--> 992\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    993\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    994\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    995\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    996\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    997\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mFLOAT_DTYPES\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    998\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    999\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1001\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sparse\u001B[38;5;241m.\u001B[39missparse(X):\n\u001B[1;32m   1002\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwith_mean:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/base.py:529\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    464\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_validate_data\u001B[39m(\n\u001B[1;32m    465\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    466\u001B[0m     X\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mno_validation\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    470\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params,\n\u001B[1;32m    471\u001B[0m ):\n\u001B[1;32m    472\u001B[0m     \u001B[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001B[39;00m\n\u001B[1;32m    473\u001B[0m \n\u001B[1;32m    474\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    527\u001B[0m \u001B[38;5;124;03m        validated.\u001B[39;00m\n\u001B[1;32m    528\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 529\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_feature_names\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    531\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_tags()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrequires_y\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m    532\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    533\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m estimator \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    534\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrequires y to be passed, but the target y is None.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    535\u001B[0m         )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/base.py:462\u001B[0m, in \u001B[0;36mBaseEstimator._check_feature_names\u001B[0;34m(self, X, reset)\u001B[0m\n\u001B[1;32m    457\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m missing_names \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m unexpected_names:\n\u001B[1;32m    458\u001B[0m     message \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    459\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFeature names must be in the same order as they were in fit.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    460\u001B[0m     )\n\u001B[0;32m--> 462\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(message)\n",
      "\u001B[0;31mValueError\u001B[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- away_batting_RBI_10RA\n- away_batting_RBI_mean\n- away_batting_RBI_skew\n- away_batting_RBI_std\n- away_batting_batting_avg_10RA\n- ...\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T07:14:26.997352Z",
     "start_time": "2024-11-20T07:14:26.997288Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "173cf2551c5538a0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
